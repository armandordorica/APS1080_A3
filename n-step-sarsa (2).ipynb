{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79449355-9e59-45f4-8338-12e403149210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "class MountainCarAgent():\n",
    "    def __init__(self, buckets=(4, 2), num_episodes=300, min_lr=0.1, min_explore=0.2, discount=0.9, decay=25, n_step=100, early_stopping_threshold=15):\n",
    "        self.early_stopping_threshold = early_stopping_threshold\n",
    "        self.buckets = buckets\n",
    "        self.num_episodes = num_episodes\n",
    "        self.min_lr = min_lr\n",
    "        self.min_explore = min_explore\n",
    "        self.discount = discount\n",
    "        self.decay = decay\n",
    "        self.n_step = n_step\n",
    "        self.env = gym.make('MountainCar-v0')\n",
    "        self.upper_bounds = [self.env.observation_space.high[0], self.env.observation_space.high[1]]\n",
    "        self.lower_bounds = [self.env.observation_space.low[0], self.env.observation_space.low[1]]\n",
    "        self.Q_table = np.zeros(self.buckets + (self.env.action_space.n,))\n",
    "        self.N = np.zeros(self.buckets + (self.env.action_space.n,))\n",
    "    \n",
    "    # Rest of the class code remains unchanged.\n",
    "\n",
    "    def get_explore_rate(self, t):\n",
    "        return max(self.min_explore, min(1., 1. - math.log10((t + 1) / self.decay)))\n",
    "\n",
    "    def get_lr(self, t):\n",
    "        return max(self.min_lr, min(1., 1. - math.log10((t + 1) / self.decay)))\n",
    "\n",
    "    def mc_update(self, current_state, new_state, reward, old_action, action,i):\n",
    "        q = self.Q_table[current_state][old_action]\n",
    "        q += (1/i)*(reward - q)\n",
    "        self.Q_table[current_state][old_action] = q\n",
    " \n",
    "    def sarsa_update(self, current_state, new_state, reward, old_action, action,i):\n",
    "        q = self.Q_table[current_state][old_action]\n",
    "        q += self.lr*(reward+self.discount*self.Q_table[new_state][action] - q)\n",
    "        self.Q_table[current_state][old_action] = q\n",
    "\n",
    "    def ql_update(self, current_state, new_state, reward, old_action, action,i):\n",
    "        q = self.Q_table[current_state][old_action]\n",
    "        q += self.lr*(reward+self.discount*np.max(self.Q_table[new_state]) - q)\n",
    "        self.Q_table[current_state][old_action] = q\n",
    "            \n",
    "    def expected_sarsa_update(self, current_state, new_state, reward, old_action, action, i):\n",
    "        q = self.Q_table[current_state][old_action]\n",
    "        \n",
    "        # Create a policy using the current Q-table\n",
    "        policy = np.ones(self.env.action_space.n) * self.explore_rate / self.env.action_space.n\n",
    "        \n",
    "        best_action = np.argmax(self.Q_table[new_state])\n",
    "        \n",
    "        policy[best_action] += (1.0 - self.explore_rate)\n",
    "        # Calculate the expected value\n",
    "        \n",
    "        expected_value = np.sum(policy * self.Q_table[new_state])\n",
    "        # Calculate the new Q-value\n",
    "        \n",
    "        q += self.lr*(reward + self.discount * expected_value - q)\n",
    "        self.Q_table[current_state][old_action] = q\n",
    "        \n",
    "        \n",
    "\n",
    "    def off_policy_expected_sarsa_update(self, current_state, new_state, reward, old_action, i):\n",
    "        q = self.Q_table[current_state][old_action]\n",
    "        \n",
    "        # Create a greedy policy using the current Q-table\n",
    "        policy = np.zeros(self.env.action_space.n)\n",
    "        \n",
    "        best_action = np.argmax(self.Q_table[new_state])\n",
    "        \n",
    "        policy[best_action] = 1.0\n",
    "        # Calculate the expected value\n",
    "        expected_value = np.sum(policy * self.Q_table[new_state])\n",
    "        \n",
    "        # Calculate the new Q-value\n",
    "        q += self.lr * (reward + self.discount * expected_value - q)\n",
    "        self.Q_table[current_state][old_action] = q\n",
    "\n",
    "\n",
    "        \n",
    "    def choose_action(self, state):\n",
    "        x = (np.random.uniform(0, 1))\n",
    "        if  x < self.explore_rate:\n",
    "            return self.env.action_space.sample()\n",
    "        else:\n",
    "            return np.argmax(self.Q_table[state])\n",
    "        \n",
    "\n",
    "    def discretize_state(self, obs):\n",
    "        discretized = list()\n",
    "        for i in range(len(obs)):\n",
    "            scaling = (obs[i] + abs(self.lower_bounds[i])) / (self.upper_bounds[i] - self.lower_bounds[i])\n",
    "            new_obs = int(np.round((self.buckets[i] - 1) * scaling))\n",
    "            new_obs = min(self.buckets[i] - 1, max(0, new_obs))\n",
    "            discretized.append(new_obs)\n",
    "        return tuple(discretized)\n",
    "    \n",
    "    def n_step_sarsa_update(self, current_state, new_state, reward, old_action, action, steps):\n",
    "        self.N[current_state][old_action] += 1\n",
    "\n",
    "        if steps < self.n_step:\n",
    "            return\n",
    "        \n",
    "        ### Note that popleft() both returns and removes the leftmost item from the deque,\n",
    "        ###so this code is both accessing and removing the entries after they've been used. \n",
    "        ### The \"mod n+1\" behavior is implicit in this design.\n",
    "\n",
    "        returns = sum(self.discount**i * self.rewards[i] for i in range(self.n_step))\n",
    "        returns += self.discount**self.n_step * self.Q_table[new_state][action]\n",
    "\n",
    "        \n",
    "        old_state, old_action = self.state_actions.popleft()\n",
    "        q = self.Q_table[old_state][old_action]\n",
    "        q += self.lr * (returns - q)\n",
    "        self.Q_table[old_state][old_action] = q\n",
    "\n",
    "    def train(self, method='mc'):\n",
    "        losses = []\n",
    "        win_counter = 0 \n",
    "        for i, e in enumerate(range(self.num_episodes)):\n",
    "            if i%100==0: \n",
    "                print(f\"episode: {i}\")\n",
    "                print(f\"self.Q_table:{self.Q_table}\")\n",
    "                \n",
    "            i += 1\n",
    "            total_R = 0\n",
    "            current_state = self.discretize_state(self.env.reset(options={(-0.6,-0.4), 0})[0])\n",
    "            \n",
    "            if i%100==0: \n",
    "                print(f\"current state:{current_state}\")\n",
    "                \n",
    "            self.lr = self.get_lr(e)\n",
    "            self.explore_rate = self.get_explore_rate(e)\n",
    "            terminated, truncated, position, end = False,False,False,False\n",
    "            old_action = 1\n",
    "            steps = 0\n",
    "\n",
    "            # Added for n-step SARSA\n",
    "            \n",
    "            ###The 'tau' from the n-step SARSA algorithm is not explicitly represented in this code. \n",
    "            ###Instead, the dequeues self.rewards and self.state_actions keep track of the last 'n' rewards\n",
    "            ### and state-action pairs.\n",
    "            ###The variable 'steps' in the train function essentially acts as the time 't' from \n",
    "            ###the n-step SARSA algorithm.\n",
    "            \n",
    "            self.rewards = deque(maxlen=self.n_step)\n",
    "            self.state_actions = deque(maxlen=self.n_step)\n",
    "\n",
    "            while not any([terminated, truncated, position, end]):\n",
    "                steps += 1\n",
    "                end = steps == num_steps_in_episode\n",
    "                ## agent selects an action (A_t) based on the current state, executes that action in the environment, \n",
    "                # and observes the resulting reward and new state. \n",
    "                action = self.choose_action(current_state)\n",
    "                obs, reward, terminated, truncated, _ = self.env.step(action)\n",
    "                \n",
    "                position = obs[0] >= 0.5\n",
    "                new_state = self.discretize_state(obs)\n",
    "                \n",
    "                self.rewards.append(reward)\n",
    "                self.state_actions.append((current_state, action))\n",
    "                \n",
    "                total_R += reward\n",
    "\n",
    "                if method == 'n_step_sarsa':\n",
    "                    self.n_step_sarsa_update(current_state, new_state, total_R, old_action, action, steps)\n",
    "                    \n",
    "                current_state = new_state\n",
    "                old_action = action\n",
    "            losses.append(total_R)\n",
    "            \n",
    "            if position == True:\n",
    "                win_counter += 1  # Increment win counter\n",
    "                print('At episode: ', e, ', Win!!!', sep='')\n",
    "                if win_counter == self.early_stopping_threshold:  # Check win counter\n",
    "                    print(f'Agent has won {self.early_stopping_threshold} times! Stopping training...')\n",
    "                    break\n",
    "                    \n",
    "#             if position == True:\n",
    "#                 print('At episode: ', e, ', Win!!!', sep='')\n",
    "\n",
    "        print('Finished training!')\n",
    "        return losses\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "       \n",
    "        self.env = gym.make('MountainCar-v0', render_mode='human')\n",
    "        current_state = self.discretize_state(self.env.reset(options={(-0.6,-0.4), 0})[0])\n",
    "        steps=0\n",
    "        termintated, truncated, position, end = False,False,False,False\n",
    "        while not any([termintated, truncated, position, end]):\n",
    "            steps+=1\n",
    "            end = steps==num_steps_in_episode\n",
    "            action = self.choose_action(current_state)\n",
    "#             print(action)\n",
    "            obs, reward, termintated, truncated, _ = self.env.step(action)\n",
    "            position = obs[0]>=0.5\n",
    "            current_state = self.discretize_state(obs)\n",
    "        if position == True:\n",
    "            print('Win!!!')\n",
    "            \n",
    "        self.env.close()\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22e82a-097b-4bf2-9412-6d27e5661850",
   "metadata": {},
   "source": [
    "### N-Step SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01791007-cba8-4e04-9feb-d3d51e21bc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0\n",
      "self.Q_table:[[[0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n",
      "current state:(1, 0)\n",
      "episode: 100\n",
      "self.Q_table:[[[  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[-10.         -10.         -10.        ]\n",
      "  [ -9.99999694 -10.          -9.99999993]]\n",
      "\n",
      " [[ -8.72379914  -4.02304814  -4.02304814]\n",
      "  [ -8.72379914  -6.42760465  -4.02304814]]\n",
      "\n",
      " [[  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]]\n",
      "current state:(1, 0)\n",
      "episode: 200\n",
      "self.Q_table:[[[ -9.96277379  -9.87976422  -9.76870259]\n",
      "  [ -8.94410754  -9.1427084   -9.30292906]]\n",
      "\n",
      " [[-10.          -9.99999999  -9.99999984]\n",
      "  [-10.         -10.         -10.        ]]\n",
      "\n",
      " [[ -9.99999609  -9.99999938 -10.        ]\n",
      "  [ -9.99999893  -9.99999904  -9.99999937]]\n",
      "\n",
      " [[  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]]\n",
      "At episode: 205, Win!!!\n",
      "At episode: 236, Win!!!\n",
      "At episode: 238, Win!!!\n",
      "At episode: 244, Win!!!\n",
      "At episode: 248, Win!!!\n",
      "At episode: 266, Win!!!\n",
      "At episode: 268, Win!!!\n",
      "At episode: 269, Win!!!\n",
      "At episode: 270, Win!!!\n",
      "At episode: 272, Win!!!\n",
      "Agent has won 10 times! Stopping training...\n",
      "Finished training!\n",
      "Win!!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def moving_average(arr, window_size=10):\n",
    "    ret = np.cumsum(arr, dtype=float)\n",
    "    ret[window_size:] = ret[window_size:] - ret[:-window_size]\n",
    "    return ret[window_size - 1:] / window_size\n",
    "\n",
    "\n",
    "\n",
    "TD_N= 100\n",
    "\n",
    "num_steps_in_episode =2000\n",
    "\n",
    "agent_n_step_sarsa = MountainCarAgent(num_episodes = 350, early_stopping_threshold=10)\n",
    "\n",
    "losses_n_step_sarsa = agent_n_step_sarsa.train(method='n_step_sarsa')\n",
    "\n",
    "agent_n_step_sarsa.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9406db-6eff-4aee-b86b-9fdfb4ee3ae2",
   "metadata": {},
   "source": [
    "<img src=\"on-policy-sarsa.png\" width=\"500\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e2cd4c0-4f37-4dcd-b4b9-dccb2cec3a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ma_losses_n_step_sarsa = moving_average(losses_n_step_sarsa, window_size=50)\n",
    "x= np.arange(0,len(ma_losses_n_step_sarsa))\n",
    "\n",
    "x = [x+50 for x in x]\n",
    "plt.plot(x, ma_losses_n_step_sarsa, label=f'{TD_N} step SARSA')\n",
    "\n",
    "plt.title(\"Moving Average (T=50) of Rewards per episode\")\n",
    "plt.xlabel(\"Episode Number\")\n",
    "plt.ylabel(\"Total Rewards\")\n",
    "plt.legend()\n",
    "\n",
    "log_df = pd.DataFrame({'rewards':ma_losses_n_step_sarsa})\n",
    "log_df['method'] = 'N step SARSA'\n",
    "log_df.to_csv(\"MountainCar_n_step_sarsa.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e900d-0c1f-454f-a0e5-7c8b175029c2",
   "metadata": {},
   "source": [
    "### Combinations of parameters that worked: \n",
    "\n",
    "<img src=\"TD(100).png\" width=\"500\"/>\n",
    "\n",
    "\n",
    "{'buckets': (4, 2), 'num_episodes': 500, 'min_lr': 0.1, 'min_explore': 0.1, 'discount': 0.9, 'decay': 25, 'n_step': 100, 'env': <TimeLimit<OrderEnforcing<PassiveEnvChecker<MountainCarEnv<MountainCar-v0>>>>>, 'upper_bounds': [0.6, 0.07], 'lower_bounds': [-1.2, -0.07], 'Q_table': array([[[ -9.99450167,  -9.99160768,  -9.99303862],\n",
    "        [ -9.96132003,  -9.87478488,  -9.87694384]],\n",
    "\n",
    "       [[ -9.99999961,  -9.99999973,  -9.9999997 ],\n",
    "        [-10.        , -10.        ,  -9.99999999]],\n",
    "\n",
    "       [[ -9.9999986 ,  -9.99999904,  -9.99999997],\n",
    "        [ -9.99999442,  -9.99999275,  -9.99998366]],\n",
    "\n",
    "       [[ -2.71      ,   0.        ,  -1.        ],\n",
    "        [ -4.68556344,  -4.68548123,  -6.86189404]]]), 'N': array([[[5.8700e+02, 1.0430e+03, 1.1120e+03],\n",
    "        [4.8500e+02, 9.2400e+02, 1.3240e+03]],\n",
    "\n",
    "       [[2.3442e+04, 1.1459e+04, 7.0120e+03],\n",
    "        [9.7270e+03, 1.0416e+04, 1.5635e+04]],\n",
    "\n",
    "       [[2.2220e+03, 1.5940e+03, 7.6700e+02],\n",
    "        [9.2900e+02, 1.9670e+03, 4.6540e+03]],\n",
    "\n",
    "       [[1.7700e+02, 5.7000e+01, 9.0000e+00],\n",
    "        [4.1600e+02, 3.9600e+02, 1.8200e+02]]]), 'lr': 0.1, 'explore_rate': 0.1, 'rewards': deque([-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0], maxlen=100), 'state_actions': deque([((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 0), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 1), 1), ((0, 1), 1), ((0, 1), 1), ((0, 1), 1), ((0, 1), 1), ((0, 1), 1), ((0, 1), 2), ((0, 1), 1), ((0, 1), 1), ((0, 1), 1), ((0, 1), 1), ((1, 1), 1), ((1, 1), 1), ((1, 1), 1), ((1, 1), 1), ((1, 1), 1), ((1, 1), 1), ((1, 1), 1), ((1, 1), 2), ((1, 1), 1), ((1, 1), 0), ((1, 1), 2), ((1, 1), 1), ((1, 1), 1), ((1, 1), 1), ((1, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 2), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 1), 1), ((2, 0), 1), ((2, 0), 0), ((2, 0), 1), ((2, 0), 1), ((2, 0), 1), ((2, 0), 1), ((2, 0), 1), ((2, 0), 1), ((2, 0), 1), ((2, 0), 1), ((2, 0), 2), ((2, 0), 1), ((2, 0), 1), ((2, 0), 1), ((2, 0), 1), ((2, 0), 1), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((1, 0), 0), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1), ((0, 0), 1)], maxlen=100)}\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc9439-3377-4826-8fe3-76c537db4a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vars(agent_n_step_sarsa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c30648-dcd5-4b37-88e6-a8c44fb44232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
